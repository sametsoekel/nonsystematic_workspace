{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c41317-4f1e-45a0-859c-a8cfe47db93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'caret' was built under R version 4.2.1\"\n"
     ]
    }
   ],
   "source": [
    "suppressPackageStartupMessages({\n",
    "    library(data.table)\n",
    "    library(tidyverse)\n",
    "    library(tidymodels)\n",
    "    library(treesnip)\n",
    "    library(caret)\n",
    "    library(keras)\n",
    "    library(tensorflow)\n",
    "    library(collapse)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a0036c-25a1-498d-aeb2-2bb9759cb503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- fread('salary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00cf177e-edd0-447a-abbd-98a1e13b12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(df) <- gsub('-','',colnames(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a76249-7eba-487b-adb2-0664ff39cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df %>% select(salary) %>% filter(salary == '>50K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce9bde6-34db-4b49-91aa-235e57f1c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode <- function(x){\n",
    "    case_when(x == '<=50K' ~ 0,\n",
    "              x == '>50K' ~ 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a57ec8-e57b-4449-8258-5e7b38216dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_data <- function(df,sparse_percentage = 0.02){\n",
    "    \n",
    "    df_new <- copy(df) \n",
    "    setDT(df_new)\n",
    "    categorical_names <- df_new %>% purrr::discard(is.numeric) %>% colnames\n",
    "\n",
    "    for(i in categorical_names){\n",
    "        features <- df_new[,unique(.SD),.SDcols = i] %>% pull\n",
    "        \n",
    "        for(j in features){\n",
    "            \n",
    "            condition_format <- 'df_new[,length(%s[%s == \"%s\"])/.N < %s]'\n",
    "            condition_command <- sprintf(condition_format,i,i,j,sparse_percentage)\n",
    "        \n",
    "            condition <- eval(parse(text = condition_command))\n",
    "            \n",
    "            if(condition){\n",
    "                sparse_format <- 'df_new[%s == \"%s\", %s := \"other\"]'\n",
    "                sparse_command <- sprintf(sparse_format,i,j,i)\n",
    "                eval(parse(text = sparse_command))\n",
    "            } \n",
    "        }\n",
    "    }\n",
    "    df_new\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da7b6f6-8629-4fcb-a780-aa4025c0bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scaling_factors <- function(df){\n",
    "    setDT(df)\n",
    "    factors <- lapply(df %>% keep(is.numeric),function(x) list(min = min(x,na.rm = T),max = max(x,na.rm = T)))\n",
    "    factors\n",
    "}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1962cf1-2b91-45bc-9246-370cf8a3b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_data <- function(df,scaling_factors,reverse = FALSE){\n",
    "    \n",
    "    data <- copy(df)\n",
    "    setDT(data)\n",
    "    for(i in names(scaling_factors)){\n",
    "        factors <- scaling_factors[[i]]\n",
    "        if(reverse){\n",
    "            data[,(i) := lapply(.SD,function(x) (x*(factors[['max']] - factors[['min']]) + factors[['min']])),.SDcols = i]\n",
    "        }else{\n",
    "            data[,(i) := lapply(.SD,function(x) (x - factors[['min']]) / (factors[['max']] - factors[['min']])),.SDcols = i]\n",
    "            data[,(i) := lapply(.SD,function(x) fifelse(is.na(x),-1,x)),.SDcols = i]\n",
    "        }  \n",
    "    }\n",
    "                                \n",
    "    catcols <- df %>% purrr::discard(is.numeric) %>% colnames\n",
    "    out <- list(scaling_factors = scaling_factors,data = data,cat_cols = catcols)\n",
    "    return(out)\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3411b5e2-342e-4afc-83c3-76a5a63c94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_set <- function(scaled_data,categorical_cols,distinct_values_on_train){\n",
    "    df <- copy(scaled_data[['data']])\n",
    "    \n",
    "    make_paste <- function(x){\n",
    "    wrapped <- sapply(x,function(x) paste0('\"',x,'\"'))\n",
    "    paste0(wrapped,collapse = ',')\n",
    "    }       \n",
    "   \n",
    "    \n",
    "    for(i in categorical_cols){\n",
    "        distincts <- distinct_values_on_train[[i]]\n",
    "        distincts <- make_paste(distincts)\n",
    "        command_format <- \"df[! %s %%in%% c(%s), %s := 'Missing']\"\n",
    "        command <- sprintf(command_format,i,distincts,i)\n",
    "        eval(parse(text = command))\n",
    "    }\n",
    "                      \n",
    "    scaled_data[['data']] <- df\n",
    "                      \n",
    "    scaled_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99bf439-dcc6-4da4-a7b6-f048076b7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_distincts <- function(scaled_data){\n",
    "    df <- copy(scaled_data[['data']])\n",
    "    \n",
    "    catcols <- scaled_data[['cat_cols']]\n",
    "    \n",
    "    distincts <- list()\n",
    "    for(i in catcols){\n",
    "        distinct_values <- df[,unique(.SD),.SDcols = i] %>% pull %>% as.character\n",
    "        distincts[[i]] <- c(distinct_values,'Missing')\n",
    "        df[,(i) := lapply(.SD,function(x) as.character(x)),.SDcols = i]\n",
    "        df[,(i) := lapply(.SD,function(x) ifelse(is.na(x),'Missing',x)),.SDcols = i]\n",
    "        df[,(i) := lapply(.SD,function(x) factor(x,levels = distincts[[i]])),.SDcols = i]\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    scaled_data[['cat_distincts']] <- distincts\n",
    "    \n",
    "    scaled_data[['data']] <- df\n",
    "                          \n",
    "    scaled_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fca393d-25f8-4640-87a2-5c7081e7eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_test_levels_to_train <- function(scaled_data,categorical_cols,distinct_values_on_train){\n",
    "    df <- copy(scaled_data[['data']])\n",
    "    \n",
    "    for(i in categorical_cols){\n",
    "        distincts <- distinct_values_on_train[[i]]\n",
    "        df[,(i) := lapply(.SD,function(x) factor(x,levels = distincts)),.SDcols = i]\n",
    "    }\n",
    "   \n",
    "    scaled_data[['data']] <- df\n",
    "    scaled_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf30cd4e-4830-444f-8dbc-48db0ebae6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data <- function(scaled_data){\n",
    "    df <- copy(scaled_data[['data']])\n",
    "    df_dummied <- recipe(df) %>% step_dummy(all_nominal()) %>% prep %>% bake(new_data = NULL)\n",
    "    scaled_data[['data']] <- df_dummied\n",
    "    scaled_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e14847e-8d47-4da6-97ee-4f206407e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_frame <- function(df,label,test = FALSE,train_frame = NULL,sparse_perc = 0.03){\n",
    "    dt <- copy(df)\n",
    "    setDT(dt)\n",
    "    if(!test){\n",
    "        target_ <- dt[[label]]\n",
    "        \n",
    "        dt[,(label) := NULL]\n",
    "    }\n",
    "    sparsed <- sparse_data(dt,sparse_percentage = sparse_perc)\n",
    "    gc()\n",
    "    base::message('Data sparsed.')\n",
    "    \n",
    "    if(!test){\n",
    "        scl <- get_scaling_factors(sparsed)\n",
    "    }else{\n",
    "        scl <- train_frame[['scaling_factors']]\n",
    "    }\n",
    "    gc()\n",
    "    base::message('Scaling factors calculated.')\n",
    "    base::message('Missing values labeled.')\n",
    "    scld <- scale_data(sparsed,scl)\n",
    "    gc()\n",
    "    base::message('Data scaled.')\n",
    "    \n",
    "    if(test){\n",
    "        scld <- clean_test_set(scld,train_frame[['cat_cols']],train_frame[['cat_distincts']])\n",
    "        base::message('Unseen values removed from test set.')\n",
    "        scld <- fetch_test_levels_to_train(scld,train_frame[['cat_cols']],train_frame[['cat_distincts']])\n",
    "        base::message('Train & test set nominal levels fetched.')\n",
    "    }\n",
    "    \n",
    "    if(!test){\n",
    "    distincted <- get_distincts(scld)\n",
    "    gc()\n",
    "    base::message('Got distinct values for nominals.')\n",
    "    }else{\n",
    "        distincted <- scld\n",
    "    }\n",
    "    \n",
    "    dummied <- dummy_data(distincted)\n",
    "    gc()\n",
    "    base::message('Data dummied.')\n",
    "    \n",
    "    if(!test){\n",
    "        dummied[['label_to_keras']] <- target_# %>% label_encode %>% keras::to_categorical()\n",
    "        dummied[['label']] <- target_ #%>% label_encode\n",
    "    }\n",
    "    \n",
    "    dummied[['data']] <- dummied[['data']] %>% as.matrix\n",
    "    base::message('All done !')\n",
    "    dummied\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92982dd2-f333-4f9e-81e7-1183b0382975",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sl <- data.table()\n",
    "\n",
    "for(i in c(LETTERS[1:10],letters[1:20])){\n",
    "    charmi <- sample(c(TRUE,FALSE),size = 1)\n",
    "    ortsec <- sample(200:500,size = 1)\n",
    "    sdsec <- sample(100:1000,size = 1)\n",
    "    if(charmi){\n",
    "        data_sl[,(i) := sample(c(LETTERS,NA),size = 2e5,replace = T)]\n",
    "    }else{\n",
    "        data_sl[,(i) := sample(c(rnorm(n = 2e2,mean = ortsec,sd = sdsec),NA),size = 2e5,replace = T)]\n",
    "    }\n",
    "}\n",
    "\n",
    "data_sl[,default := sample(c('No','Yes'),size = 2e5,prob = c(.93,.07),replace = T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bd8aee4-1bc1-45fe-9491-c613050dcb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(571)\n",
    "#dk <- copy(iris)\n",
    "traindex <- createDataPartition(df[['salary']],p = .8,times = 1,list = FALSE) %>% as.numeric\n",
    "train_set <- df[traindex,]\n",
    "test_set <- df[-traindex,]\n",
    "#train_set <- dk[traindex,]\n",
    "#test_set <- dk[-traindex,] %>% select(-default) %>% filter(student != 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27763e61-c6e4-4c2d-813a-60579f0f1749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary\n",
       "    <=50K      >50K \n",
       "0.7591846 0.2408154 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set %>% select(salary) %>% table %>% prop.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b14783-465f-4ca1-b239-85039f54bd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary\n",
       "    <=50K      >50K \n",
       "0.7592138 0.2407862 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set %>% select(salary) %>% table %>% prop.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a232fb71-efcd-4748-b40b-7a0e58ab6860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data sparsed.\n",
      "\n",
      "Scaling factors calculated.\n",
      "\n",
      "Missing values labeled.\n",
      "\n",
      "Data scaled.\n",
      "\n",
      "Got distinct values for nominals.\n",
      "\n",
      "Data dummied.\n",
      "\n",
      "All done !\n",
      "\n",
      "Data sparsed.\n",
      "\n",
      "Scaling factors calculated.\n",
      "\n",
      "Missing values labeled.\n",
      "\n",
      "Data scaled.\n",
      "\n",
      "Unseen values removed from test set.\n",
      "\n",
      "Train & test set nominal levels fetched.\n",
      "\n",
      "Data dummied.\n",
      "\n",
      "All done !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ok <- train_set %>% make_frame(label = 'salary')\n",
    "test_ok <- test_set %>% select(-salary) %>% make_frame(label = 'salary',test = T,train_frame = train_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb4bce17-618e-4b95-a336-568d8a7056c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 <- function(y_true, y_pred){\n",
    "    y_pred = k_round(y_pred)\n",
    "    \n",
    "    tp = k_sum(k_cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = k_sum(k_cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = k_sum(k_cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = k_sum(k_cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + k_epsilon())\n",
    "    r = tp / (tp + fn + k_epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+k_epsilon())\n",
    "    f1 = tf$where(tf$math$is_nan(f1), tf$zeros_like(f1), f1)\n",
    "    return(k_mean(f1,axis = 1))\n",
    "}\n",
    "\n",
    "f1_loss <- function(y_true, y_pred){\n",
    "    #y_pred = k_round(y_pred)\n",
    "    tp = k_sum(k_cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = k_sum(k_cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = k_sum(k_cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = k_sum(k_cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + k_epsilon())\n",
    "    r = tp / (tp + fn + k_epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+k_epsilon())\n",
    "    f1 = tf$where(tf$math$is_nan(f1), tf$zeros_like(f1), f1)\n",
    "    return(1 - k_mean(f1,axis = 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21ddddd4-a97c-4346-a0f8-73d46750c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_ <- caret::createFolds(train_ok[['label']],k = 5)\n",
    "\n",
    "folds <- 1:length(folds_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b270b17e-5ef8-4be5-bf84-4e92e4e2845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neurons <- ncol(train_ok[['data']][folds_[[1]],]) \n",
    "output_neurons <- 2\n",
    "\n",
    "nofsample <- nrow(train_ok[['data']][folds_[[1]],])\n",
    "\n",
    "alpha <- 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9314dc76-5d0c-4d77-a7e7-8bf227becee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numofneuron <- nofsample / (alpha * (input_neurons + output_neurons))\n",
    "\n",
    "numofneuron <- numofneuron - output_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89631e62-bffb-46e0-958d-86ed7a2cf25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "45.3636363636364"
      ],
      "text/latex": [
       "45.3636363636364"
      ],
      "text/markdown": [
       "45.3636363636364"
      ],
      "text/plain": [
       "[1] 45.36364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numofneuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01769dce-b6eb-4bac-a22a-f86b53c2f281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>22</li><li>15</li><li>8</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 22\n",
       "\\item 15\n",
       "\\item 8\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 22\n",
       "2. 15\n",
       "3. 8\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 22 15  8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_dist1 <- base::seq(from = numofneuron,to = output_neurons,length.out = 5)\n",
    "layer_dist <- layer_dist1[-1]/base::sum(layer_dist1[-1])*numofneuron\n",
    "layer_disto <- layer_dist %>% ceiling %>% .[1:3]\n",
    "\n",
    "layer_disto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a3523fc-7f61-4238-8796-0edb8a36a672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded Tensorflow version 2.10.0-dev20220614\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Fold 1 F1 : 0.7'"
      ],
      "text/latex": [
       "'Fold 1 F1 : 0.7'"
      ],
      "text/markdown": [
       "'Fold 1 F1 : 0.7'"
      ],
      "text/plain": [
       "[1] \"Fold 1 F1 : 0.7\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Best threshold for Fold 1 is : 0.33'"
      ],
      "text/latex": [
       "'Best threshold for Fold 1 is : 0.33'"
      ],
      "text/markdown": [
       "'Best threshold for Fold 1 is : 0.33'"
      ],
      "text/plain": [
       "[1] \"Best threshold for Fold 1 is : 0.33\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Fold 2 F1 : 0.7'"
      ],
      "text/latex": [
       "'Fold 2 F1 : 0.7'"
      ],
      "text/markdown": [
       "'Fold 2 F1 : 0.7'"
      ],
      "text/plain": [
       "[1] \"Fold 2 F1 : 0.7\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Best threshold for Fold 2 is : 0.64'"
      ],
      "text/latex": [
       "'Best threshold for Fold 2 is : 0.64'"
      ],
      "text/markdown": [
       "'Best threshold for Fold 2 is : 0.64'"
      ],
      "text/plain": [
       "[1] \"Best threshold for Fold 2 is : 0.64\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Fold 3 F1 : 0.69'"
      ],
      "text/latex": [
       "'Fold 3 F1 : 0.69'"
      ],
      "text/markdown": [
       "'Fold 3 F1 : 0.69'"
      ],
      "text/plain": [
       "[1] \"Fold 3 F1 : 0.69\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Best threshold for Fold 3 is : 0.63'"
      ],
      "text/latex": [
       "'Best threshold for Fold 3 is : 0.63'"
      ],
      "text/markdown": [
       "'Best threshold for Fold 3 is : 0.63'"
      ],
      "text/plain": [
       "[1] \"Best threshold for Fold 3 is : 0.63\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Fold 4 F1 : 0.7'"
      ],
      "text/latex": [
       "'Fold 4 F1 : 0.7'"
      ],
      "text/markdown": [
       "'Fold 4 F1 : 0.7'"
      ],
      "text/plain": [
       "[1] \"Fold 4 F1 : 0.7\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Best threshold for Fold 4 is : 0.03'"
      ],
      "text/latex": [
       "'Best threshold for Fold 4 is : 0.03'"
      ],
      "text/markdown": [
       "'Best threshold for Fold 4 is : 0.03'"
      ],
      "text/plain": [
       "[1] \"Best threshold for Fold 4 is : 0.03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Fold 5 F1 : 0.68'"
      ],
      "text/latex": [
       "'Fold 5 F1 : 0.68'"
      ],
      "text/markdown": [
       "'Fold 5 F1 : 0.68'"
      ],
      "text/plain": [
       "[1] \"Fold 5 F1 : 0.68\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Best threshold for Fold 5 is : 0.01'"
      ],
      "text/latex": [
       "'Best threshold for Fold 5 is : 0.01'"
      ],
      "text/markdown": [
       "'Best threshold for Fold 5 is : 0.01'"
      ],
      "text/plain": [
       "[1] \"Best threshold for Fold 5 is : 0.01\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'CV Mean F1 : 0.694102496127787'"
      ],
      "text/latex": [
       "'CV Mean F1 : 0.694102496127787'"
      ],
      "text/markdown": [
       "'CV Mean F1 : 0.694102496127787'"
      ],
      "text/plain": [
       "[1] \"CV Mean F1 : 0.694102496127787\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed <- 1923\n",
    "preds_keras <- list()\n",
    "errors <- c()\n",
    "\n",
    "for(i in folds){\n",
    "    train_indices <- setdiff(folds,i) \n",
    "    test_indices <- i\n",
    "    \n",
    "    train_x <- train_ok[['data']][unlist(folds_[train_indices]),] %>% na.omit\n",
    "    test_x <- train_ok[['data']][unlist(folds_[test_indices]),] %>% na.omit\n",
    "    \n",
    "    target_data <- test_ok[['data']]\n",
    "    \n",
    "    train_y <- train_ok[['label']][unlist(folds_[train_indices])]\n",
    "    test_y <- train_ok[['label']][unlist(folds_[test_indices])]\n",
    "    \n",
    "    train_y2 <- train_y %>% label_encode %>% as.matrix %>% to_categorical\n",
    "    test_y2 <- test_y %>% label_encode %>% as.matrix %>% to_categorical\n",
    "    \n",
    "    tf$random$set_seed(seed = seed)\n",
    "\n",
    "    reticulate::py_set_seed(seed = seed)\n",
    "\n",
    "    model <- keras_model_sequential()\n",
    "    \n",
    "\n",
    "    model %>%\n",
    "    layer_dense(units = ceiling(numofneuron), activation = 'relu', input_shape = c(input_neurons)) %>%\n",
    "    #layer_dense(units = layer_disto[7], activation = 'relu') %>%\n",
    "    layer_dense(units = c(output_neurons),activation = 'softmax')\n",
    "    \n",
    "    model %>% compile(\n",
    "      loss = f1_loss,#f1_loss,\n",
    "      optimizer =optimizer_rmsprop(learning_rate = 0.01),\n",
    "      metrics = c(f1)\n",
    "    )\n",
    "    \n",
    "    wgh <- sum(test_y == '<=50K')/sum(test_y == '>50K')\n",
    "    \n",
    "    history <- model %>% fit(\n",
    "      train_x, train_y2, \n",
    "      epochs = 1000, batch_size = 1024, \n",
    "      validation_data = list(test_x,test_y2),\n",
    "      callbacks = list(callback_early_stopping(\n",
    "                        monitor = \"val_loss\",\n",
    "                        patience = 100,\n",
    "                        verbose = 1,\n",
    "                        mode = \"auto\",\n",
    "                        restore_best_weights = TRUE\n",
    "                        )\n",
    "    ),\n",
    "    class_weight = list('0' = sum(test_y == '>50K'),'1' = sum(test_y == '<=50K'))\n",
    "    )\n",
    "    \n",
    "    preds <- model %>% predict(test_x)  %>% .[,2]\n",
    "    \n",
    "    # fold thresholding \n",
    "    thresholds <- data.table()\n",
    "    for(j in seq(from = 0.01,to = 0.9,by = 0.01)){\n",
    "        obs <- test_y %>% label_encode\n",
    "        prd <- +(preds >= j)\n",
    "        if(sum(prd) == 0){\n",
    "            next\n",
    "        }\n",
    "        f1_clc <- f_meas_vec(truth = factor(obs,levels = 0:1),estimate = factor(prd,levels = 0:1),event_level = 'second')\n",
    "        fold_row <- data.table(threshold = j,f1 = f1_clc)\n",
    "        thresholds <- rbindlist(list(thresholds,fold_row))\n",
    "    }\n",
    "    \n",
    "    best_threshold <- thresholds %>% filter(f1 == max(f1)) %>% select(threshold) %>% pull %>% .[1]\n",
    "    #best_threshold <- 0.5\n",
    "    error <- thresholds %>% filter(f1 == max(f1)) %>% select(f1) %>% pull %>% .[1]\n",
    "    #error <- accuracy_vec(truth = factor(obs,levels = 0:2),estimate = factor(preds,levels = 0:2))#,event_level = 'second')\n",
    "    IRdisplay::display('**************----------**************')\n",
    "    IRdisplay::display(sprintf('Fold %s F1 : %s',i,round(error,2)))\n",
    "    errors[i] <- error\n",
    "    IRdisplay::display(sprintf('Best threshold for Fold %s is : %s',i,best_threshold))\n",
    "    \n",
    "    \n",
    "    \n",
    "    preds_target <- model %>% predict(target_data) %>% .[,2]\n",
    "    \n",
    "    preds_target <- +(preds_target >= best_threshold)\n",
    "    \n",
    "    preds_keras[[i]] <- preds_target\n",
    "    \n",
    "    rm(model)\n",
    "    gc()\n",
    "}\n",
    "IRdisplay::display('**************----------**************')\n",
    "IRdisplay::display(sprintf('CV Mean F1 : %s',mean(errors,na.rm = T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d0944e5-0366-4809-bd33-e4f1f68cfa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "krs <- preds_keras %>% as.data.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "253ddb91-bcb1-4915-b936-3085c37e1a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(krs) <- paste0('Fold',1:length(folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a03a8828-29c0-426f-8ad4-42c1988e04be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pmin(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "900a110c-fac9-42ac-bf24-4f4044d42e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "krs <- krs %>% rowwise %>% mutate(prd = pmin(fmode(c(Fold1,Fold2,Fold3,Fold4,Fold5)),1L)) %>% as.data.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1de6cefc-1744-486f-a7d9-f799db4ea4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#krs[,prd := +(prd >= 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5488aa6a-297c-4f34-bf01-d12f3615875c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary\n",
       "    <=50K      >50K \n",
       "0.7592138 0.2407862 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[-traindex,] %>% select(salary) %>% table %>% prop.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68c5f72b-92c2-4f73-9e24-c4e73e2ba7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prd\n",
       "        0         1 \n",
       "0.7383292 0.2616708 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "krs %>% select(prd) %>% table %>% prop.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4f3fcbf-d1c7-4701-ba54-c7cb1120358e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 1 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>f_meas</td><td>binary</td><td>0.690709</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 3\n",
       "\\begin{tabular}{lll}\n",
       " .metric & .estimator & .estimate\\\\\n",
       " <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t f\\_meas & binary & 0.690709\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 3\n",
       "\n",
       "| .metric &lt;chr&gt; | .estimator &lt;chr&gt; | .estimate &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| f_meas | binary | 0.690709 |\n",
       "\n"
      ],
      "text/plain": [
       "  .metric .estimator .estimate\n",
       "1 f_meas  binary     0.690709 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set%>% select(salary) %>%\n",
    "transmute(obs = label_encode(salary)) %>%\n",
    "bind_cols(krs %>% select(prd)) %>%\n",
    "f_meas(truth = factor(obs,levels = 0:1),estimate = factor(prd,levels = 0:1),event_level = 'second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1604d80-a657-4f64-a443-cd2f5124a58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Fold 1 F1 : 0.7'"
      ],
      "text/latex": [
       "'Fold 1 F1 : 0.7'"
      ],
      "text/markdown": [
       "'Fold 1 F1 : 0.7'"
      ],
      "text/plain": [
       "[1] \"Fold 1 F1 : 0.7\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Best threshold for Fold 1 is : 0.46'"
      ],
      "text/latex": [
       "'Best threshold for Fold 1 is : 0.46'"
      ],
      "text/markdown": [
       "'Best threshold for Fold 1 is : 0.46'"
      ],
      "text/plain": [
       "[1] \"Best threshold for Fold 1 is : 0.46\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Fold 2 F1 : 0.71'"
      ],
      "text/latex": [
       "'Fold 2 F1 : 0.71'"
      ],
      "text/markdown": [
       "'Fold 2 F1 : 0.71'"
      ],
      "text/plain": [
       "[1] \"Fold 2 F1 : 0.71\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Best threshold for Fold 2 is : 0.53'"
      ],
      "text/latex": [
       "'Best threshold for Fold 2 is : 0.53'"
      ],
      "text/markdown": [
       "'Best threshold for Fold 2 is : 0.53'"
      ],
      "text/plain": [
       "[1] \"Best threshold for Fold 2 is : 0.53\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Fold 3 F1 : 0.71'"
      ],
      "text/latex": [
       "'Fold 3 F1 : 0.71'"
      ],
      "text/markdown": [
       "'Fold 3 F1 : 0.71'"
      ],
      "text/plain": [
       "[1] \"Fold 3 F1 : 0.71\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Best threshold for Fold 3 is : 0.47'"
      ],
      "text/latex": [
       "'Best threshold for Fold 3 is : 0.47'"
      ],
      "text/markdown": [
       "'Best threshold for Fold 3 is : 0.47'"
      ],
      "text/plain": [
       "[1] \"Best threshold for Fold 3 is : 0.47\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Fold 4 F1 : 0.71'"
      ],
      "text/latex": [
       "'Fold 4 F1 : 0.71'"
      ],
      "text/markdown": [
       "'Fold 4 F1 : 0.71'"
      ],
      "text/plain": [
       "[1] \"Fold 4 F1 : 0.71\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Best threshold for Fold 4 is : 0.47'"
      ],
      "text/latex": [
       "'Best threshold for Fold 4 is : 0.47'"
      ],
      "text/markdown": [
       "'Best threshold for Fold 4 is : 0.47'"
      ],
      "text/plain": [
       "[1] \"Best threshold for Fold 4 is : 0.47\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Fold 5 F1 : 0.69'"
      ],
      "text/latex": [
       "'Fold 5 F1 : 0.69'"
      ],
      "text/markdown": [
       "'Fold 5 F1 : 0.69'"
      ],
      "text/plain": [
       "[1] \"Fold 5 F1 : 0.69\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Best threshold for Fold 5 is : 0.43'"
      ],
      "text/latex": [
       "'Best threshold for Fold 5 is : 0.43'"
      ],
      "text/markdown": [
       "'Best threshold for Fold 5 is : 0.43'"
      ],
      "text/plain": [
       "[1] \"Best threshold for Fold 5 is : 0.43\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'cat_features' is meaningless because column types are taken from data.frame.\n",
      "Please, convert categorical columns to factors manually.\n",
      "Parameter 'cat_features' is meaningless because column types are taken from data.frame.\n",
      "Please, convert categorical columns to factors manually.\n",
      "Parameter 'cat_features' is meaningless because column types are taken from data.frame.\n",
      "Please, convert categorical columns to factors manually.\n",
      "Parameter 'cat_features' is meaningless because column types are taken from data.frame.\n",
      "Please, convert categorical columns to factors manually.\n",
      "Parameter 'cat_features' is meaningless because column types are taken from data.frame.\n",
      "Please, convert categorical columns to factors manually.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'**************----------**************'"
      ],
      "text/latex": [
       "'**************----------**************'"
      ],
      "text/markdown": [
       "'**************----------**************'"
      ],
      "text/plain": [
       "[1] \"**************----------**************\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'CV Mean F1 : 0.706108733747836'"
      ],
      "text/latex": [
       "'CV Mean F1 : 0.706108733747836'"
      ],
      "text/markdown": [
       "'CV Mean F1 : 0.706108733747836'"
      ],
      "text/plain": [
       "[1] \"CV Mean F1 : 0.706108733747836\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors <- c()\n",
    "preds_cb <- list()\n",
    "set.seed(1)\n",
    "\n",
    "rcp <- recipe(salary ~ .,data = train_set) %>% step_string2factor(all_nominal_predictors())\n",
    "\n",
    "\n",
    "spc <- boost_tree(learn_rate = 0.01) %>%\n",
    "set_mode('classification') %>%\n",
    "#set_engine('xgboost',scale_pos_weight = sqrt(ww)) #%>%\n",
    "set_engine('catboost',auto_class_weights = 'SqrtBalanced',custom_loss = 'F1:use_weights=False',eval_metric = 'F1:use_weights=False') \n",
    "\n",
    "\n",
    "wf <- workflow() %>% add_recipe(rcp) %>% add_model(spc)\n",
    "\n",
    "rsmpl <- vfold_cv(train_set,strata = salary,v = 5)\n",
    "\n",
    "ctrl <- control_bayes(verbose = T,event_level = 'second')\n",
    "\n",
    "metrk <- yardstick::metric_set(f_meas)\n",
    "\n",
    "#tuned <- tune_bayes(wf,resamples = rsmpl,iter = 5,metrics = metrk,control = ctrl)\n",
    "\n",
    "#best_param <- tuned %>% select_best('f_meas')\n",
    "\n",
    "#wf <- wf %>% finalize_workflow(best_param)\n",
    "\n",
    "for(i in folds){\n",
    "    train_indices <- setdiff(folds,i) \n",
    "    test_indices <- i\n",
    "    \n",
    "    #train_x <- train_ok[['data']][unlist(folds_[train_indices]),] %>% na.omit\n",
    "    #test_x <- train_ok[['data']][unlist(folds_[test_indices]),] %>% na.omit\n",
    "    train_x <- train_set[unlist(folds_[train_indices]),] %>% select(-salary)\n",
    "    test_x <- train_set[unlist(folds_[test_indices]),] %>% select(-salary)\n",
    "    target_data <- test_set %>% as.data.table \n",
    "    \n",
    "    train_y <- train_set[unlist(folds_[train_indices])] %>% select(salary) %>% pull\n",
    "    test_y <- train_set[unlist(folds_[test_indices])] %>% select(salary) %>% pull\n",
    "    #train_y <- train_ok[['label']][unlist(folds_[train_indices])]\n",
    "    #test_y <- train_ok[['label']][unlist(folds_[test_indices])]\n",
    "    \n",
    "    train_df <- train_x %>% as.data.table %>% mutate(salary = train_y)\n",
    "    test_df <- test_x %>% as.data.table %>% mutate(salary = test_y)\n",
    "    \n",
    "    \n",
    "    ww <- train_df %>% summarise(length(salary[salary == '<=50K'])/length(salary[salary == '>50K'])) %>% pull\n",
    "       \n",
    "    mod <- wf %>% fit(train_df)\n",
    "    \n",
    "    prds <- mod %>% predict(test_df,type='prob') %>% .[,2] %>% pull\n",
    "    \n",
    "    thresholds <- data.table()\n",
    "    for(j in seq(from = 0.03,to = 0.7,by = 0.01)){\n",
    "        obs <- test_df %>% select(salary) %>% pull %>% label_encode\n",
    "        prd <- +(prds >= j)\n",
    "        if(sum(prd) == 0){\n",
    "            next\n",
    "        }\n",
    "        f1_clc <- f_meas_vec(truth = factor(obs,levels = 0:1),estimate = factor(prd,levels = 0:1),event_level = 'second')\n",
    "        fold_row <- data.table(threshold = j,f1 = f1_clc)\n",
    "        thresholds <- rbindlist(list(thresholds,fold_row))\n",
    "    }\n",
    "    \n",
    "    best_threshold <- thresholds %>% filter(f1 == max(f1)) %>% select(threshold) %>% pull %>% .[1]\n",
    "    error <- thresholds %>% filter(f1 == max(f1)) %>% select(f1) %>% pull %>% .[1]\n",
    "    \n",
    "    #error <- prds %>% bind_cols(ts %>% select(salary)) %>%\n",
    "    #f_meas(truth = .pred_class,estimate = factor(salary,levels = c('<=50K','>50K')),event_level = 'second') %>%\n",
    "    #select(.estimate) %>%\n",
    "    #pull \n",
    "    \n",
    "    IRdisplay::display('**************----------**************')\n",
    "    IRdisplay::display(sprintf('Fold %s F1 : %s',i,round(error,2)))\n",
    "    errors[i] <- error\n",
    "    IRdisplay::display(sprintf('Best threshold for Fold %s is : %s',i,best_threshold))\n",
    "    \n",
    "    prds_targ <- mod %>% predict(target_data,type = 'prob') %>% .[,2] %>% pull\n",
    "    \n",
    "    prds_targ <- +(prds_targ >= best_threshold)\n",
    "    \n",
    "    preds_cb[[i]] <- prds_targ\n",
    "}\n",
    "\n",
    "\n",
    "IRdisplay::display('**************----------**************')\n",
    "IRdisplay::display(sprintf('CV Mean F1 : %s',mean(errors,na.rm = T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19a1c6fe-299e-443b-bd28-d6fabe43f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb <- preds_cb %>% as.data.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "780a93b1-df9e-4fd2-a2e0-6902ba2220f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(cb) <- paste0('Fold',1:length(folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a60db5b-3324-46f0-807e-df5c53e65669",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb <- cb %>% rowwise %>% mutate(prd = fmode(c(Fold1,Fold2,Fold3,Fold4,Fold5))) %>% as.data.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "119a6e54-04d4-49d1-982c-aa132e4a456f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in select(., salary): 'test_set' nesnesi bulunamadı\n",
     "output_type": "error",
     "traceback": [
      "Error in select(., salary): 'test_set' nesnesi bulunamadı\nTraceback:\n",
      "1. test_set %>% select(salary) %>% bind_cols(cb %>% select(prd)) %>% \n .     f_meas(truth = factor(ifelse(salary == \"<=50K\", 0, 1), levels = 0:1), \n .         estimate = factor(prd, levels = 0:1), event_level = \"second\")",
      "2. f_meas(., truth = factor(ifelse(salary == \"<=50K\", 0, 1), levels = 0:1), \n .     estimate = factor(prd, levels = 0:1), event_level = \"second\")",
      "3. bind_cols(., cb %>% select(prd))",
      "4. list2(...)",
      "5. select(., salary)"
     ]
    }
   ],
   "source": [
    "test_set %>%\n",
    "select(salary) %>%\n",
    "bind_cols(cb %>% select(prd)) %>%\n",
    "f_meas(truth = factor(ifelse(salary == '<=50K',0,1),levels= 0:1),estimate = factor(prd,levels = 0:1),event_level = 'second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb6f81-ba12-4eaa-96e7-5d2ef6a681b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "?scale_pos_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c44a1dc5-40db-4e9c-8945-e8223a0b0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96edc572-6bae-414c-a2cb-b2810a07cf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'xgboost'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    slice\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cfd5f60-8f59-4516-8732-7df94a37c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod %>% extract_fit_engine -> md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6fe6a2d0-4b62-4ffa-8b77-47d63533ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- iris[,-5] \n",
    "y <- iris[,5] %>% as.numeric - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7231cef9-6357-465c-a60d-b67c7e3cbc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt <- xgb.DMatrix(data = as.matrix(x),label = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ab3eaf95-5490-4d8c-a2bc-72ff288021dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk <- catboost::catboost.load_pool(data = x,label = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3b39cb8f-fab4-455a-a3ae-16531aa5a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod <- xgb.train(data = dt,nrounds = 2,num_class = 3,objective = 'multi:softprob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ba8299d5-6829-4cc0-a799-846c543cf514",
   "metadata": {},
   "outputs": [],
   "source": [
    "prm <- list(learning_rate = 0.01,iterations = 200,verbose = 1,loss_function = 'MultiClass',eval_metric = 'TotalF1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "309a09e5-e378-44cf-aa2f-b685d633aec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe.0:\tlearn: 0.9666366\ttest: 0.9666366\tbest: 0.9666366 (0)\ttotal: 707us\tremaining: 141ms\n",
      "1:\tlearn: 0.9733227\ttest: 0.9733227\tbest: 0.9733227 (1)\ttotal: 1.24ms\tremaining: 123ms\n",
      "2:\tlearn: 0.9666633\ttest: 0.9666633\tbest: 0.9733227 (1)\ttotal: 1.92ms\tremaining: 126ms\n",
      "3:\tlearn: 0.9599840\ttest: 0.9599840\tbest: 0.9733227 (1)\ttotal: 2.93ms\tremaining: 143ms\n",
      "4:\tlearn: 0.9666633\ttest: 0.9666633\tbest: 0.9733227 (1)\ttotal: 3.54ms\tremaining: 138ms\n",
      "5:\tlearn: 0.9666633\ttest: 0.9666633\tbest: 0.9733227 (1)\ttotal: 4.17ms\tremaining: 135ms\n",
      "6:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 4.82ms\tremaining: 133ms\n",
      "7:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 5.42ms\tremaining: 130ms\n",
      "8:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 6.03ms\tremaining: 128ms\n",
      "9:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 6.69ms\tremaining: 127ms\n",
      "10:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 7.37ms\tremaining: 127ms\n",
      "11:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 7.97ms\tremaining: 125ms\n",
      "12:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 8.67ms\tremaining: 125ms\n",
      "13:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 9.34ms\tremaining: 124ms\n",
      "14:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 10ms\tremaining: 123ms\n",
      "15:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 10.8ms\tremaining: 124ms\n",
      "16:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 11.5ms\tremaining: 123ms\n",
      "17:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 12.3ms\tremaining: 124ms\n",
      "18:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 12.9ms\tremaining: 123ms\n",
      "19:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 13.6ms\tremaining: 122ms\n",
      "20:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 14.4ms\tremaining: 123ms\n",
      "21:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 15.4ms\tremaining: 124ms\n",
      "22:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 16.1ms\tremaining: 124ms\n",
      "23:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 16.8ms\tremaining: 123ms\n",
      "24:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 17.3ms\tremaining: 121ms\n",
      "25:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 18ms\tremaining: 121ms\n",
      "26:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 18.6ms\tremaining: 119ms\n",
      "27:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 19.3ms\tremaining: 119ms\n",
      "28:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 20ms\tremaining: 118ms\n",
      "29:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 20.7ms\tremaining: 117ms\n",
      "30:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 21.2ms\tremaining: 116ms\n",
      "31:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 21.9ms\tremaining: 115ms\n",
      "32:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 22.7ms\tremaining: 115ms\n",
      "33:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 23.3ms\tremaining: 114ms\n",
      "34:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 23.9ms\tremaining: 113ms\n",
      "35:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 24.4ms\tremaining: 111ms\n",
      "36:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 24.9ms\tremaining: 110ms\n",
      "37:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 25.4ms\tremaining: 108ms\n",
      "38:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 25.9ms\tremaining: 107ms\n",
      "39:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 26.4ms\tremaining: 106ms\n",
      "40:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 26.9ms\tremaining: 104ms\n",
      "41:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 27.4ms\tremaining: 103ms\n",
      "42:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 27.9ms\tremaining: 102ms\n",
      "43:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 28.3ms\tremaining: 100ms\n",
      "44:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 28.8ms\tremaining: 99.2ms\n",
      "45:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 29.3ms\tremaining: 98.1ms\n",
      "46:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 29.5ms\tremaining: 96ms\n",
      "47:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 29.9ms\tremaining: 94.5ms\n",
      "48:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 30.3ms\tremaining: 93.5ms\n",
      "49:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 30.8ms\tremaining: 92.4ms\n",
      "50:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 31.4ms\tremaining: 91.8ms\n",
      "51:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 32.1ms\tremaining: 91.2ms\n",
      "52:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 32.6ms\tremaining: 90.3ms\n",
      "53:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 33.1ms\tremaining: 89.4ms\n",
      "54:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 33.6ms\tremaining: 88.5ms\n",
      "55:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 34.1ms\tremaining: 87.6ms\n",
      "56:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 34.6ms\tremaining: 86.7ms\n",
      "57:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 35.1ms\tremaining: 85.9ms\n",
      "58:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 35.6ms\tremaining: 85ms\n",
      "59:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 36.1ms\tremaining: 84.2ms\n",
      "60:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 36.6ms\tremaining: 83.4ms\n",
      "61:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 37.1ms\tremaining: 82.6ms\n",
      "62:\tlearn: 0.9533287\ttest: 0.9533287\tbest: 0.9733227 (1)\ttotal: 37.7ms\tremaining: 81.9ms\n",
      "63:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 38.2ms\tremaining: 81.2ms\n",
      "64:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 38.6ms\tremaining: 80.1ms\n",
      "65:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 39.1ms\tremaining: 79.4ms\n",
      "66:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 39.7ms\tremaining: 78.7ms\n",
      "67:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 40.2ms\tremaining: 78ms\n",
      "68:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 40.9ms\tremaining: 77.7ms\n",
      "69:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 41.5ms\tremaining: 77ms\n",
      "70:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 42ms\tremaining: 76.3ms\n",
      "71:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 42.5ms\tremaining: 75.6ms\n",
      "72:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 43.1ms\tremaining: 74.9ms\n",
      "73:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 43.6ms\tremaining: 74.3ms\n",
      "74:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 44.2ms\tremaining: 73.6ms\n",
      "75:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 44.7ms\tremaining: 73ms\n",
      "76:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 45.3ms\tremaining: 72.4ms\n",
      "77:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 45.5ms\tremaining: 71.2ms\n",
      "78:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 46.3ms\tremaining: 70.9ms\n",
      "79:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 46.8ms\tremaining: 70.2ms\n",
      "80:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 47.3ms\tremaining: 69.5ms\n",
      "81:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 47.8ms\tremaining: 68.8ms\n",
      "82:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 48.4ms\tremaining: 68.2ms\n",
      "83:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 48.9ms\tremaining: 67.5ms\n",
      "84:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 49.1ms\tremaining: 66.5ms\n",
      "85:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 49.7ms\tremaining: 65.8ms\n",
      "86:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 50.2ms\tremaining: 65.2ms\n",
      "87:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 50.7ms\tremaining: 64.5ms\n",
      "88:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 51.2ms\tremaining: 63.8ms\n",
      "89:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 51.7ms\tremaining: 63.2ms\n",
      "90:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 52.3ms\tremaining: 62.6ms\n",
      "91:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 52.8ms\tremaining: 62ms\n",
      "92:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 53.4ms\tremaining: 61.4ms\n",
      "93:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 53.9ms\tremaining: 60.8ms\n",
      "94:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 54.4ms\tremaining: 60.1ms\n",
      "95:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 54.8ms\tremaining: 59.3ms\n",
      "96:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 55.3ms\tremaining: 58.7ms\n",
      "97:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 55.8ms\tremaining: 58.1ms\n",
      "98:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 56.3ms\tremaining: 57.5ms\n",
      "99:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 56.9ms\tremaining: 56.9ms\n",
      "100:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 57.3ms\tremaining: 56.2ms\n",
      "101:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 57.8ms\tremaining: 55.5ms\n",
      "102:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 58.3ms\tremaining: 54.9ms\n",
      "103:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 58.8ms\tremaining: 54.2ms\n",
      "104:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 59.2ms\tremaining: 53.6ms\n",
      "105:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 59.7ms\tremaining: 52.9ms\n",
      "106:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 60.2ms\tremaining: 52.4ms\n",
      "107:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 60.8ms\tremaining: 51.8ms\n",
      "108:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 61.4ms\tremaining: 51.2ms\n",
      "109:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 62ms\tremaining: 50.7ms\n",
      "110:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 62.5ms\tremaining: 50.1ms\n",
      "111:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 63ms\tremaining: 49.5ms\n",
      "112:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 63.5ms\tremaining: 48.9ms\n",
      "113:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 64ms\tremaining: 48.3ms\n",
      "114:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 64.3ms\tremaining: 47.6ms\n",
      "115:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 64.9ms\tremaining: 47ms\n",
      "116:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 65.4ms\tremaining: 46.4ms\n",
      "117:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 66ms\tremaining: 45.9ms\n",
      "118:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 66.5ms\tremaining: 45.3ms\n",
      "119:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 67ms\tremaining: 44.7ms\n",
      "120:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 67.5ms\tremaining: 44.1ms\n",
      "121:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 68.1ms\tremaining: 43.5ms\n",
      "122:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 68.6ms\tremaining: 43ms\n",
      "123:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 69.2ms\tremaining: 42.4ms\n",
      "124:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 69.7ms\tremaining: 41.8ms\n",
      "125:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 70.3ms\tremaining: 41.3ms\n",
      "126:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 70.8ms\tremaining: 40.7ms\n",
      "127:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 71.3ms\tremaining: 40.1ms\n",
      "128:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 71.8ms\tremaining: 39.5ms\n",
      "129:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 72.4ms\tremaining: 39ms\n",
      "130:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 72.9ms\tremaining: 38.4ms\n",
      "131:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 73.4ms\tremaining: 37.8ms\n",
      "132:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 73.9ms\tremaining: 37.2ms\n",
      "133:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 74.5ms\tremaining: 36.7ms\n",
      "134:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 75ms\tremaining: 36.1ms\n",
      "135:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 75.5ms\tremaining: 35.5ms\n",
      "136:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 76.1ms\tremaining: 35ms\n",
      "137:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 76.3ms\tremaining: 34.3ms\n",
      "138:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 76.9ms\tremaining: 33.7ms\n",
      "139:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 77.4ms\tremaining: 33.2ms\n",
      "140:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 77.9ms\tremaining: 32.6ms\n",
      "141:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 78.5ms\tremaining: 32.1ms\n",
      "142:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 79ms\tremaining: 31.5ms\n",
      "143:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 79.6ms\tremaining: 31ms\n",
      "144:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 80.2ms\tremaining: 30.4ms\n",
      "145:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 80.8ms\tremaining: 29.9ms\n",
      "146:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 81.3ms\tremaining: 29.3ms\n",
      "147:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 81.8ms\tremaining: 28.8ms\n",
      "148:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 82.4ms\tremaining: 28.2ms\n",
      "149:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 82.9ms\tremaining: 27.6ms\n",
      "150:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 83.4ms\tremaining: 27.1ms\n",
      "151:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 83.9ms\tremaining: 26.5ms\n",
      "152:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 84.4ms\tremaining: 25.9ms\n",
      "153:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 84.9ms\tremaining: 25.4ms\n",
      "154:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 85.4ms\tremaining: 24.8ms\n",
      "155:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 85.9ms\tremaining: 24.2ms\n",
      "156:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 86.4ms\tremaining: 23.7ms\n",
      "157:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 86.9ms\tremaining: 23.1ms\n",
      "158:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 87.3ms\tremaining: 22.5ms\n",
      "159:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 87.9ms\tremaining: 22ms\n",
      "160:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 88.4ms\tremaining: 21.4ms\n",
      "161:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 88.9ms\tremaining: 20.9ms\n",
      "162:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 89.5ms\tremaining: 20.3ms\n",
      "163:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 90.1ms\tremaining: 19.8ms\n",
      "164:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 90.6ms\tremaining: 19.2ms\n",
      "165:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 91.1ms\tremaining: 18.7ms\n",
      "166:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 91.6ms\tremaining: 18.1ms\n",
      "167:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 92.1ms\tremaining: 17.6ms\n",
      "168:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 92.6ms\tremaining: 17ms\n",
      "169:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 93.2ms\tremaining: 16.4ms\n",
      "170:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 93.7ms\tremaining: 15.9ms\n",
      "171:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 94.1ms\tremaining: 15.3ms\n",
      "172:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 94.6ms\tremaining: 14.8ms\n",
      "173:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 95.2ms\tremaining: 14.2ms\n",
      "174:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 95.7ms\tremaining: 13.7ms\n",
      "175:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 96.3ms\tremaining: 13.1ms\n",
      "176:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 96.8ms\tremaining: 12.6ms\n",
      "177:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 97.3ms\tremaining: 12ms\n",
      "178:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 97.9ms\tremaining: 11.5ms\n",
      "179:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 98.4ms\tremaining: 10.9ms\n",
      "180:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 98.9ms\tremaining: 10.4ms\n",
      "181:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 99.4ms\tremaining: 9.83ms\n",
      "182:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 100ms\tremaining: 9.29ms\n",
      "183:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 100ms\tremaining: 8.74ms\n",
      "184:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 101ms\tremaining: 8.19ms\n",
      "185:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 101ms\tremaining: 7.64ms\n",
      "186:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 102ms\tremaining: 7.09ms\n",
      "187:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 103ms\tremaining: 6.54ms\n",
      "188:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 103ms\tremaining: 6ms\n",
      "189:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 104ms\tremaining: 5.45ms\n",
      "190:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 104ms\tremaining: 4.9ms\n",
      "191:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 104ms\tremaining: 4.35ms\n",
      "192:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 105ms\tremaining: 3.8ms\n",
      "193:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 105ms\tremaining: 3.26ms\n",
      "194:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 106ms\tremaining: 2.71ms\n",
      "195:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 106ms\tremaining: 2.17ms\n",
      "196:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 107ms\tremaining: 1.62ms\n",
      "197:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 107ms\tremaining: 1.08ms\n",
      "198:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 108ms\tremaining: 540us\n",
      "199:\tlearn: 0.9600000\ttest: 0.9600000\tbest: 0.9733227 (1)\ttotal: 108ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9733226624\n",
      "bestIteration = 1\n",
      "\n",
      "Shrink model to first 2 iterations.\n"
     ]
    }
   ],
   "source": [
    "mod_cb <- catboost.train(learn_pool = kk,test_pool = kk,params = prm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fa6944da-d631-4e07-846d-20132e39c3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\"><tr><td>loss-functions {keras}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Loss functions</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Loss functions\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre><code class='language-R'>loss_binary_crossentropy(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  from_logits = FALSE,\n",
       "  label_smoothing = 0,\n",
       "  axis = -1L,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"binary_crossentropy\"\n",
       ")\n",
       "\n",
       "loss_categorical_crossentropy(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  from_logits = FALSE,\n",
       "  label_smoothing = 0L,\n",
       "  axis = -1L,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"categorical_crossentropy\"\n",
       ")\n",
       "\n",
       "loss_categorical_hinge(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"categorical_hinge\"\n",
       ")\n",
       "\n",
       "loss_cosine_similarity(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  axis = -1L,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"cosine_similarity\"\n",
       ")\n",
       "\n",
       "loss_hinge(y_true, y_pred, ..., reduction = \"auto\", name = \"hinge\")\n",
       "\n",
       "loss_huber(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  delta = 1,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"huber_loss\"\n",
       ")\n",
       "\n",
       "loss_kullback_leibler_divergence(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"kl_divergence\"\n",
       ")\n",
       "\n",
       "loss_kl_divergence(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"kl_divergence\"\n",
       ")\n",
       "\n",
       "loss_logcosh(y_true, y_pred, ..., reduction = \"auto\", name = \"log_cosh\")\n",
       "\n",
       "loss_mean_absolute_error(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"mean_absolute_error\"\n",
       ")\n",
       "\n",
       "loss_mean_absolute_percentage_error(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"mean_absolute_percentage_error\"\n",
       ")\n",
       "\n",
       "loss_mean_squared_error(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"mean_squared_error\"\n",
       ")\n",
       "\n",
       "loss_mean_squared_logarithmic_error(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"mean_squared_logarithmic_error\"\n",
       ")\n",
       "\n",
       "loss_poisson(y_true, y_pred, ..., reduction = \"auto\", name = \"poisson\")\n",
       "\n",
       "loss_sparse_categorical_crossentropy(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  from_logits = FALSE,\n",
       "  axis = -1L,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"sparse_categorical_crossentropy\"\n",
       ")\n",
       "\n",
       "loss_squared_hinge(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"squared_hinge\"\n",
       ")\n",
       "</code></pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table>\n",
       "<tr valign=\"top\"><td><code>y_true</code></td>\n",
       "<td>\n",
       "<p>Ground truth values. shape = <code style=\"white-space: pre;\">&#8288;[batch_size, d1, .. dN]&#8288;</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>y_pred</code></td>\n",
       "<td>\n",
       "<p>The predicted values. shape = <code style=\"white-space: pre;\">&#8288;[batch_size, d1, .. dN]&#8288;</code>.\n",
       "(Tensor of the same shape as <code>y_true</code>)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>from_logits</code></td>\n",
       "<td>\n",
       "<p>Whether <code>y_pred</code> is expected to be a logits tensor. By\n",
       "default we assume that <code>y_pred</code> encodes a probability distribution.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>label_smoothing</code></td>\n",
       "<td>\n",
       "<p>Float in <code style=\"white-space: pre;\">&#8288;[0, 1]&#8288;</code>. If <code style=\"white-space: pre;\">&#8288;&gt; 0&#8288;</code> then smooth the labels.\n",
       "For example, if <code>0.1</code>, use <code>0.1 / num_classes</code> for non-target labels and\n",
       "<code>0.9 + 0.1 / num_classes</code> for target labels.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>axis</code></td>\n",
       "<td>\n",
       "<p>The axis along which to compute crossentropy (the features axis).\n",
       "Axis is 1-based (e.g, first axis is <code>axis=1</code>). Defaults to <code>-1</code> (the last axis).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p>Additional arguments passed on to the Python callable (for forward\n",
       "and backwards compatibility).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>reduction</code></td>\n",
       "<td>\n",
       "<p>Only applicable if <code>y_true</code> and <code>y_pred</code> are missing. Type\n",
       "of <code>keras$losses$Reduction</code> to apply to loss. Default value is <code>AUTO</code>.\n",
       "<code>AUTO</code> indicates that the reduction option will be determined by the usage\n",
       "context. For almost all cases this defaults to <code>SUM_OVER_BATCH_SIZE</code>. When\n",
       "used with <code>tf$distribute$Strategy</code>, outside of built-in training loops such\n",
       "as <code>compile</code> and <code>fit</code>, using <code>AUTO</code> or <code>SUM_OVER_BATCH_SIZE</code> will raise an\n",
       "error. Please see this custom training <a href=\"https://www.tensorflow.org/tutorials/distribute/custom_training\">tutorial</a> for more\n",
       "details.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>name</code></td>\n",
       "<td>\n",
       "<p>Only applicable if <code>y_true</code> and <code>y_pred</code> are missing. Optional\n",
       "name for the Loss instance.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>delta</code></td>\n",
       "<td>\n",
       "<p>A float, the point where the Huber loss function changes from a\n",
       "quadratic to linear.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>Loss functions for model training. These are typically supplied in\n",
       "the <code>loss</code> parameter of the <code>compile.keras.engine.training.Model()</code>\n",
       "function.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>If called with <code>y_true</code> and <code>y_pred</code>, then the corresponding loss is\n",
       "evaluated and the result returned (as a tensor). Alternatively, if <code>y_true</code>\n",
       "and <code>y_pred</code> are missing, then a callable is returned that will compute the\n",
       "loss function and, by default, reduce the loss to a scalar tensor; see the\n",
       "<code>reduction</code> parameter for details. (The callable is a typically a class\n",
       "instance that inherits from <code>keras$losses$Loss</code>).\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>binary_crossentropy</h3>\n",
       "\n",
       "<p>Computes the binary crossentropy loss.\n",
       "</p>\n",
       "<p><code>label_smoothing</code> details: Float in <code style=\"white-space: pre;\">&#8288;[0, 1]&#8288;</code>. If <code style=\"white-space: pre;\">&#8288;&gt; 0&#8288;</code> then smooth the labels\n",
       "by squeezing them towards 0.5 That is, using <code>1. - 0.5 * label_smoothing</code>\n",
       "for the target class and <code>0.5 * label_smoothing</code> for the non-target class.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>categorical_crossentropy</h3>\n",
       "\n",
       "<p>Computes the categorical crossentropy loss.\n",
       "</p>\n",
       "<p>When using the categorical_crossentropy loss, your targets should be in\n",
       "categorical format (e.g. if you have 10 classes, the target for each sample\n",
       "should be a 10-dimensional vector that is all-zeros except for a 1 at the\n",
       "index corresponding to the class of the sample). In order to convert\n",
       "integer targets into categorical targets, you can use the Keras utility\n",
       "function <code>to_categorical()</code>:\n",
       "</p>\n",
       "<p><code>categorical_labels &lt;- to_categorical(int_labels, num_classes = NULL)</code>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>huber</h3>\n",
       "\n",
       "<p>Computes Huber loss value.\n",
       "For each value x in <code>error = y_true - y_pred</code>:\n",
       "</p>\n",
       "<div class=\"sourceCode\"><pre>loss = 0.5 * x^2                  if |x| &lt;= d\n",
       "loss = d * |x| - 0.5 * d^2        if |x| &gt; d\n",
       "</pre></div>\n",
       "<p>where d is <code>delta</code>. See: https://en.wikipedia.org/wiki/Huber_loss\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>log_cosh</h3>\n",
       "\n",
       "<p>Logarithm of the hyperbolic cosine of the prediction error.\n",
       "</p>\n",
       "<p><code>log(cosh(x))</code> is approximately equal to <code>(x ** 2) / 2</code> for small <code>x</code> and\n",
       "to <code>abs(x) - log(2)</code> for large <code>x</code>. This means that 'logcosh' works mostly\n",
       "like the mean squared error, but will not be so strongly affected by the\n",
       "occasional wildly incorrect prediction. However, it may return NaNs if the\n",
       "intermediate value <code>cosh(y_pred - y_true)</code> is too large to be represented\n",
       "in the chosen precision.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>compile.keras.engine.training.Model()</code>,\n",
       "<code>loss_binary_crossentropy()</code>\n",
       "</p>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>keras</em> version 2.9.0 ]</div>\n",
       "</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{loss-functions}{Loss functions}{loss.Rdash.functions}\n",
       "\\aliasA{\"binary\\_crossentropy\",}{loss-functions}{\"binary.Rul.crossentropy\",}\n",
       "\\aliasA{\"BinaryCrossentropy\"}{loss-functions}{\"BinaryCrossentropy\"}\n",
       "\\aliasA{loss\\_binary\\_crossentropy}{loss-functions}{loss.Rul.binary.Rul.crossentropy}\n",
       "\\aliasA{loss\\_categorical\\_crossentropy}{loss-functions}{loss.Rul.categorical.Rul.crossentropy}\n",
       "\\aliasA{loss\\_categorical\\_hinge}{loss-functions}{loss.Rul.categorical.Rul.hinge}\n",
       "\\aliasA{loss\\_cosine\\_similarity}{loss-functions}{loss.Rul.cosine.Rul.similarity}\n",
       "\\aliasA{loss\\_hinge}{loss-functions}{loss.Rul.hinge}\n",
       "\\aliasA{loss\\_huber}{loss-functions}{loss.Rul.huber}\n",
       "\\aliasA{loss\\_kl\\_divergence}{loss-functions}{loss.Rul.kl.Rul.divergence}\n",
       "\\aliasA{loss\\_kullback\\_leibler\\_divergence}{loss-functions}{loss.Rul.kullback.Rul.leibler.Rul.divergence}\n",
       "\\aliasA{loss\\_logcosh}{loss-functions}{loss.Rul.logcosh}\n",
       "\\aliasA{loss\\_mean\\_absolute\\_error}{loss-functions}{loss.Rul.mean.Rul.absolute.Rul.error}\n",
       "\\aliasA{loss\\_mean\\_absolute\\_percentage\\_error}{loss-functions}{loss.Rul.mean.Rul.absolute.Rul.percentage.Rul.error}\n",
       "\\aliasA{loss\\_mean\\_squared\\_error}{loss-functions}{loss.Rul.mean.Rul.squared.Rul.error}\n",
       "\\aliasA{loss\\_mean\\_squared\\_logarithmic\\_error}{loss-functions}{loss.Rul.mean.Rul.squared.Rul.logarithmic.Rul.error}\n",
       "\\aliasA{loss\\_poisson}{loss-functions}{loss.Rul.poisson}\n",
       "\\aliasA{loss\\_sparse\\_categorical\\_crossentropy}{loss-functions}{loss.Rul.sparse.Rul.categorical.Rul.crossentropy}\n",
       "\\aliasA{loss\\_squared\\_hinge}{loss-functions}{loss.Rul.squared.Rul.hinge}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Loss functions\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "loss_binary_crossentropy(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  from_logits = FALSE,\n",
       "  label_smoothing = 0,\n",
       "  axis = -1L,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"binary_crossentropy\"\n",
       ")\n",
       "\n",
       "loss_categorical_crossentropy(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  from_logits = FALSE,\n",
       "  label_smoothing = 0L,\n",
       "  axis = -1L,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"categorical_crossentropy\"\n",
       ")\n",
       "\n",
       "loss_categorical_hinge(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"categorical_hinge\"\n",
       ")\n",
       "\n",
       "loss_cosine_similarity(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  axis = -1L,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"cosine_similarity\"\n",
       ")\n",
       "\n",
       "loss_hinge(y_true, y_pred, ..., reduction = \"auto\", name = \"hinge\")\n",
       "\n",
       "loss_huber(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  delta = 1,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"huber_loss\"\n",
       ")\n",
       "\n",
       "loss_kullback_leibler_divergence(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"kl_divergence\"\n",
       ")\n",
       "\n",
       "loss_kl_divergence(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"kl_divergence\"\n",
       ")\n",
       "\n",
       "loss_logcosh(y_true, y_pred, ..., reduction = \"auto\", name = \"log_cosh\")\n",
       "\n",
       "loss_mean_absolute_error(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"mean_absolute_error\"\n",
       ")\n",
       "\n",
       "loss_mean_absolute_percentage_error(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"mean_absolute_percentage_error\"\n",
       ")\n",
       "\n",
       "loss_mean_squared_error(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"mean_squared_error\"\n",
       ")\n",
       "\n",
       "loss_mean_squared_logarithmic_error(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"mean_squared_logarithmic_error\"\n",
       ")\n",
       "\n",
       "loss_poisson(y_true, y_pred, ..., reduction = \"auto\", name = \"poisson\")\n",
       "\n",
       "loss_sparse_categorical_crossentropy(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  from_logits = FALSE,\n",
       "  axis = -1L,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"sparse_categorical_crossentropy\"\n",
       ")\n",
       "\n",
       "loss_squared_hinge(\n",
       "  y_true,\n",
       "  y_pred,\n",
       "  ...,\n",
       "  reduction = \"auto\",\n",
       "  name = \"squared_hinge\"\n",
       ")\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{y\\_true}] Ground truth values. shape = \\AsIs{\\texttt{[batch\\_size, d1, .. dN]}}.\n",
       "\n",
       "\\item[\\code{y\\_pred}] The predicted values. shape = \\AsIs{\\texttt{[batch\\_size, d1, .. dN]}}.\n",
       "(Tensor of the same shape as \\code{y\\_true})\n",
       "\n",
       "\\item[\\code{from\\_logits}] Whether \\code{y\\_pred} is expected to be a logits tensor. By\n",
       "default we assume that \\code{y\\_pred} encodes a probability distribution.\n",
       "\n",
       "\\item[\\code{label\\_smoothing}] Float in \\AsIs{\\texttt{[0, 1]}}. If \\AsIs{\\texttt{> 0}} then smooth the labels.\n",
       "For example, if \\code{0.1}, use \\code{0.1 / num\\_classes} for non-target labels and\n",
       "\\code{0.9 + 0.1 / num\\_classes} for target labels.\n",
       "\n",
       "\\item[\\code{axis}] The axis along which to compute crossentropy (the features axis).\n",
       "Axis is 1-based (e.g, first axis is \\code{axis=1}). Defaults to \\code{-1} (the last axis).\n",
       "\n",
       "\\item[\\code{...}] Additional arguments passed on to the Python callable (for forward\n",
       "and backwards compatibility).\n",
       "\n",
       "\\item[\\code{reduction}] Only applicable if \\code{y\\_true} and \\code{y\\_pred} are missing. Type\n",
       "of \\code{keras\\$losses\\$Reduction} to apply to loss. Default value is \\code{AUTO}.\n",
       "\\code{AUTO} indicates that the reduction option will be determined by the usage\n",
       "context. For almost all cases this defaults to \\code{SUM\\_OVER\\_BATCH\\_SIZE}. When\n",
       "used with \\code{tf\\$distribute\\$Strategy}, outside of built-in training loops such\n",
       "as \\code{compile} and \\code{fit}, using \\code{AUTO} or \\code{SUM\\_OVER\\_BATCH\\_SIZE} will raise an\n",
       "error. Please see this custom training \\Rhref{https://www.tensorflow.org/tutorials/distribute/custom_training}{tutorial} for more\n",
       "details.\n",
       "\n",
       "\\item[\\code{name}] Only applicable if \\code{y\\_true} and \\code{y\\_pred} are missing. Optional\n",
       "name for the Loss instance.\n",
       "\n",
       "\\item[\\code{delta}] A float, the point where the Huber loss function changes from a\n",
       "quadratic to linear.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "Loss functions for model training. These are typically supplied in\n",
       "the \\code{loss} parameter of the \\code{\\LinkA{compile.keras.engine.training.Model()}{compile.keras.engine.training.Model}}\n",
       "function.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "If called with \\code{y\\_true} and \\code{y\\_pred}, then the corresponding loss is\n",
       "evaluated and the result returned (as a tensor). Alternatively, if \\code{y\\_true}\n",
       "and \\code{y\\_pred} are missing, then a callable is returned that will compute the\n",
       "loss function and, by default, reduce the loss to a scalar tensor; see the\n",
       "\\code{reduction} parameter for details. (The callable is a typically a class\n",
       "instance that inherits from \\code{keras\\$losses\\$Loss}).\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Section}{binary\\_crossentropy}\n",
       "\n",
       "\n",
       "Computes the binary crossentropy loss.\n",
       "\n",
       "\\code{label\\_smoothing} details: Float in \\AsIs{\\texttt{[0, 1]}}. If \\AsIs{\\texttt{> 0}} then smooth the labels\n",
       "by squeezing them towards 0.5 That is, using \\code{1. - 0.5 * label\\_smoothing}\n",
       "for the target class and \\code{0.5 * label\\_smoothing} for the non-target class.\n",
       "\\end{Section}\n",
       "%\n",
       "\\begin{Section}{categorical\\_crossentropy}\n",
       "\n",
       "\n",
       "Computes the categorical crossentropy loss.\n",
       "\n",
       "When using the categorical\\_crossentropy loss, your targets should be in\n",
       "categorical format (e.g. if you have 10 classes, the target for each sample\n",
       "should be a 10-dimensional vector that is all-zeros except for a 1 at the\n",
       "index corresponding to the class of the sample). In order to convert\n",
       "integer targets into categorical targets, you can use the Keras utility\n",
       "function \\code{\\LinkA{to\\_categorical()}{to.Rul.categorical}}:\n",
       "\n",
       "\\code{categorical\\_labels <- to\\_categorical(int\\_labels, num\\_classes = NULL)}\n",
       "\\end{Section}\n",
       "%\n",
       "\\begin{Section}{huber}\n",
       "\n",
       "\n",
       "Computes Huber loss value.\n",
       "For each value x in \\code{error = y\\_true - y\\_pred}:\n",
       "\n",
       "\\begin{alltt}loss = 0.5 * x^2                  if |x| <= d\n",
       "loss = d * |x| - 0.5 * d^2        if |x| > d\n",
       "\\end{alltt}\n",
       "\n",
       "\n",
       "where d is \\code{delta}. See: https://en.wikipedia.org/wiki/Huber\\_loss\n",
       "\\end{Section}\n",
       "%\n",
       "\\begin{Section}{log\\_cosh}\n",
       "\n",
       "\n",
       "Logarithm of the hyperbolic cosine of the prediction error.\n",
       "\n",
       "\\code{log(cosh(x))} is approximately equal to \\code{(x ** 2) / 2} for small \\code{x} and\n",
       "to \\code{abs(x) - log(2)} for large \\code{x}. This means that 'logcosh' works mostly\n",
       "like the mean squared error, but will not be so strongly affected by the\n",
       "occasional wildly incorrect prediction. However, it may return NaNs if the\n",
       "intermediate value \\code{cosh(y\\_pred - y\\_true)} is too large to be represented\n",
       "in the chosen precision.\n",
       "\\end{Section}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{\\LinkA{compile.keras.engine.training.Model()}{compile.keras.engine.training.Model}},\n",
       "\\code{\\LinkA{loss\\_binary\\_crossentropy()}{loss.Rul.binary.Rul.crossentropy}}\n",
       "\\end{SeeAlso}"
      ],
      "text/plain": [
       "loss-functions              package:keras              R Documentation\n",
       "\n",
       "_\bL_\bo_\bs_\bs _\bf_\bu_\bn_\bc_\bt_\bi_\bo_\bn_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Loss functions\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     loss_binary_crossentropy(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       from_logits = FALSE,\n",
       "       label_smoothing = 0,\n",
       "       axis = -1L,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"binary_crossentropy\"\n",
       "     )\n",
       "     \n",
       "     loss_categorical_crossentropy(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       from_logits = FALSE,\n",
       "       label_smoothing = 0L,\n",
       "       axis = -1L,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"categorical_crossentropy\"\n",
       "     )\n",
       "     \n",
       "     loss_categorical_hinge(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"categorical_hinge\"\n",
       "     )\n",
       "     \n",
       "     loss_cosine_similarity(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       axis = -1L,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"cosine_similarity\"\n",
       "     )\n",
       "     \n",
       "     loss_hinge(y_true, y_pred, ..., reduction = \"auto\", name = \"hinge\")\n",
       "     \n",
       "     loss_huber(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       delta = 1,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"huber_loss\"\n",
       "     )\n",
       "     \n",
       "     loss_kullback_leibler_divergence(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"kl_divergence\"\n",
       "     )\n",
       "     \n",
       "     loss_kl_divergence(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"kl_divergence\"\n",
       "     )\n",
       "     \n",
       "     loss_logcosh(y_true, y_pred, ..., reduction = \"auto\", name = \"log_cosh\")\n",
       "     \n",
       "     loss_mean_absolute_error(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"mean_absolute_error\"\n",
       "     )\n",
       "     \n",
       "     loss_mean_absolute_percentage_error(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"mean_absolute_percentage_error\"\n",
       "     )\n",
       "     \n",
       "     loss_mean_squared_error(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"mean_squared_error\"\n",
       "     )\n",
       "     \n",
       "     loss_mean_squared_logarithmic_error(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"mean_squared_logarithmic_error\"\n",
       "     )\n",
       "     \n",
       "     loss_poisson(y_true, y_pred, ..., reduction = \"auto\", name = \"poisson\")\n",
       "     \n",
       "     loss_sparse_categorical_crossentropy(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       from_logits = FALSE,\n",
       "       axis = -1L,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"sparse_categorical_crossentropy\"\n",
       "     )\n",
       "     \n",
       "     loss_squared_hinge(\n",
       "       y_true,\n",
       "       y_pred,\n",
       "       ...,\n",
       "       reduction = \"auto\",\n",
       "       name = \"squared_hinge\"\n",
       "     )\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "  y_true: Ground truth values. shape = [batch_size, d1, .. dN].\n",
       "\n",
       "  y_pred: The predicted values. shape = [batch_size, d1, .. dN].\n",
       "          (Tensor of the same shape as 'y_true')\n",
       "\n",
       "from_logits: Whether 'y_pred' is expected to be a logits tensor. By\n",
       "          default we assume that 'y_pred' encodes a probability\n",
       "          distribution.\n",
       "\n",
       "label_smoothing: Float in [0, 1]. If > 0 then smooth the labels. For\n",
       "          example, if '0.1', use '0.1 / num_classes' for non-target\n",
       "          labels and '0.9 + 0.1 / num_classes' for target labels.\n",
       "\n",
       "    axis: The axis along which to compute crossentropy (the features\n",
       "          axis). Axis is 1-based (e.g, first axis is 'axis=1').\n",
       "          Defaults to '-1' (the last axis).\n",
       "\n",
       "     ...: Additional arguments passed on to the Python callable (for\n",
       "          forward and backwards compatibility).\n",
       "\n",
       "reduction: Only applicable if 'y_true' and 'y_pred' are missing. Type\n",
       "          of 'keras$losses$Reduction' to apply to loss. Default value\n",
       "          is 'AUTO'. 'AUTO' indicates that the reduction option will be\n",
       "          determined by the usage context. For almost all cases this\n",
       "          defaults to 'SUM_OVER_BATCH_SIZE'. When used with\n",
       "          'tf$distribute$Strategy', outside of built-in training loops\n",
       "          such as 'compile' and 'fit', using 'AUTO' or\n",
       "          'SUM_OVER_BATCH_SIZE' will raise an error. Please see this\n",
       "          custom training tutorial for more details.\n",
       "\n",
       "    name: Only applicable if 'y_true' and 'y_pred' are missing.\n",
       "          Optional name for the Loss instance.\n",
       "\n",
       "   delta: A float, the point where the Huber loss function changes from\n",
       "          a quadratic to linear.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     Loss functions for model training. These are typically supplied in\n",
       "     the 'loss' parameter of the\n",
       "     'compile.keras.engine.training.Model()' function.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     If called with 'y_true' and 'y_pred', then the corresponding loss\n",
       "     is evaluated and the result returned (as a tensor). Alternatively,\n",
       "     if 'y_true' and 'y_pred' are missing, then a callable is returned\n",
       "     that will compute the loss function and, by default, reduce the\n",
       "     loss to a scalar tensor; see the 'reduction' parameter for\n",
       "     details. (The callable is a typically a class instance that\n",
       "     inherits from 'keras$losses$Loss').\n",
       "\n",
       "_\bb_\bi_\bn_\ba_\br_\by__\bc_\br_\bo_\bs_\bs_\be_\bn_\bt_\br_\bo_\bp_\by:\n",
       "\n",
       "     Computes the binary crossentropy loss.\n",
       "\n",
       "     'label_smoothing' details: Float in [0, 1]. If > 0 then smooth the\n",
       "     labels by squeezing them towards 0.5 That is, using '1. - 0.5 *\n",
       "     label_smoothing' for the target class and '0.5 * label_smoothing'\n",
       "     for the non-target class.\n",
       "\n",
       "_\bc_\ba_\bt_\be_\bg_\bo_\br_\bi_\bc_\ba_\bl__\bc_\br_\bo_\bs_\bs_\be_\bn_\bt_\br_\bo_\bp_\by:\n",
       "\n",
       "     Computes the categorical crossentropy loss.\n",
       "\n",
       "     When using the categorical_crossentropy loss, your targets should\n",
       "     be in categorical format (e.g. if you have 10 classes, the target\n",
       "     for each sample should be a 10-dimensional vector that is\n",
       "     all-zeros except for a 1 at the index corresponding to the class\n",
       "     of the sample). In order to convert integer targets into\n",
       "     categorical targets, you can use the Keras utility function\n",
       "     'to_categorical()':\n",
       "\n",
       "     'categorical_labels <- to_categorical(int_labels, num_classes =\n",
       "     NULL)'\n",
       "\n",
       "_\bh_\bu_\bb_\be_\br:\n",
       "\n",
       "     Computes Huber loss value. For each value x in 'error = y_true -\n",
       "     y_pred':\n",
       "\n",
       "     loss = 0.5 * x^2                  if |x| <= d\n",
       "     loss = d * |x| - 0.5 * d^2        if |x| > d\n",
       "     \n",
       "     where d is 'delta'. See: https://en.wikipedia.org/wiki/Huber_loss\n",
       "\n",
       "_\bl_\bo_\bg__\bc_\bo_\bs_\bh:\n",
       "\n",
       "     Logarithm of the hyperbolic cosine of the prediction error.\n",
       "\n",
       "     'log(cosh(x))' is approximately equal to '(x ** 2) / 2' for small\n",
       "     'x' and to 'abs(x) - log(2)' for large 'x'. This means that\n",
       "     'logcosh' works mostly like the mean squared error, but will not\n",
       "     be so strongly affected by the occasional wildly incorrect\n",
       "     prediction. However, it may return NaNs if the intermediate value\n",
       "     'cosh(y_pred - y_true)' is too large to be represented in the\n",
       "     chosen precision.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     'compile.keras.engine.training.Model()',\n",
       "     'loss_binary_crossentropy()'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b164990-36a9-40ea-9e52-11a7a1cfdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr(prds,'dim') <- c(150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5ee99e1-55cc-4ac7-a509-f853bb155fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod <- catboost.train(kk,params = prm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
